# [AI Repository](https://ryuseonghan.github.io/AI-Repository)

A curated list of resources about artificial intelligence (AI).

Maintained by [Seonghan Ryu](https://github.com/ryuseonghan).

Inspired by the [awsome lists](https://github.com/sindresorhus/awesome).

## Sharing

[![Facebook](https://github.com/ryuseonghan/NLP-Repository/blob/master/img/fb.png?raw=true)](https://www.facebook.com/sharer/sharer.php?u=https://ryuseonghan.github.io/AI-Repository)
[![Twitter](https://github.com/ryuseonghan/NLP-Repository/blob/master/img/tt.png?raw=true)](http://twitter.com/home?status=https://ryuseonghan.github.io/AI-Repository)

## AI in General

Video Lectures

- [Convolutional Neural Networks for Visual Recognition (Stanford)](http://cs231n.stanford.edu/), Fei-Fei Li
 et al., 2017 [[Video]](https://www.youtube.com/watch?v=NfnWJUyUJYU&list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC) [[Note]](http://cs231n.github.io/)
- [Learn TensorFlow and deep learning, without a Ph.D.](https://cloud.google.com/blog/big-data/2017/01/learn-tensorflow-and-deep-learning-without-a-phd), Martin Görner, 2017
- [Tensorflow for Deep Learning Research (Stanford)](http://web.stanford.edu/class/cs20si/index.html), Chip Huyen, 2017
- [인공지능 및 기계학습 개론](http://seslab.kaist.ac.kr/xe2/page_GBex27), 문일철, 2016
- [Deep Learning Summer School, Montreal 2016](http://videolectures.net/deeplearning2016_montreal/), 2016
- [Deep Learning by Google](https://www.udacity.com/course/deep-learning--ud730), Vincent Vanhoucke, 2016
- [모두를 위한 머신러닝 / 딥러닝](http://hunkim.github.io/ml/), 김성훈, 2016
- [C++로 배우는 Deep Learning](http://blog.naver.com/atelierjpro), 홍정모, 2016
- [Deep Learning (Oxford)](https://www.youtube.com/playlist?list=PLE6Wd9FR--EfW8dtjAuPoTuPcqmOV53Fu), Nando de Freitas, 2015
- [Practical Deep Learning For Coders](http://course.fast.ai/), Jeremy Howard, 2016
- [Machine Learning](https://www.youtube.com/playlist?list=PLZ9qNFMHZ-A4rycgrgOYma6zxF4BZGGPW), Andrew Ng, Coursera, 2014
- [Neural Networks](http://info.usherbrooke.ca/hlarochelle/neural_networks/content.html), Hugo Larochelle, 2013

Books

- [Hands-On Machine Learning with Scikit-Learn and TensorFlow](https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/), Aurélien Géron, O'Reilly Media, Inc., 2017
- [PRML (Korean ver.)](http://norman3.github.io/prml/), Kiho Hong, Github, 2016
- [TensorFlow For Machine Intelligence: A hands-on introduction to learning algorithms](https://www.amazon.com/TensorFlow-Machine-Intelligence-hands-introduction-ebook/dp/B01IZ43JV4), Sam Abrahams et al., Bleeding Edge Press, 2016
- [Deep Learning](http://www.deeplearningbook.org/), Ian Goodfellow et al., MIT Press, 2016
- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/), Michael Nielsen, Determination Press, 2015
- [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/index.html), Gareth James et al., Springer, 2013
- [The Elements of Statistical Learning](https://statweb.stanford.edu/~tibs/ElemStatLearn/), Trevor Hastie et al., Springer, 2009 [[PDF]](http://statweb.stanford.edu/~tibs/ElemStatLearn/printings/ESLII_print10.pdf)

Related Conferences & Workshops

- AAAI Conference on Artificial Intelligence (AAAI)
- Annual Conference on Neural Information Processing Systems (NIPS)
- International Conference on Machine Learning (ICML)
- International Joint Conference on Artificial Intelligence (IJCAI)
- IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
- IEEE International Conference on Data Mining (ICDM)
- International Conference on Knowledge Discovery and Data Mining (KDD)

Tools

- [TensorFlow](https://www.tensorflow.org/)
- [Theano](http://www.deeplearning.net/software/theano/)
- [Keras](https://keras.io/)
- [Open AI Gym](https://gym.openai.com/)
- [The Microsoft Cognitive Toolkit](https://www.microsoft.com/en-us/research/product/cognitive-toolkit/)

Reference

- [awesome-rnn](https://github.com/kjw0612/awesome-rnn)
- [awesome-deep-learning-papers](https://github.com/terryum/awesome-deep-learning-papers)

## Deep Learning

- [On the Origin of Deep Learning](https://arxiv.org/abs/1702.07800), Haohan Wang et al., arXiv, 2017
- [UFLDL: Unsupervised Feature Learning and Deep Learning](http://ufldl.stanford.edu/tutorial/), Andrew Ng et al., 2013 [[Wiki]](http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial)

## Data Science

- [Team Data Science Process Documentation by Microsoft Azure](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/)
- [The Data Science Process - A Visual Guide to Standard Procedures in Data Science](https://towardsdatascience.com/the-data-science-process-a19eb7ebc41b)

## TensorFlow

- [TensorFlow: A proposal of good practices for files, folders and models architecture](https://blog.metaflow.fr/tensorflow-a-proposal-of-good-practices-for-files-folders-and-models-architecture-f23171501ae3), Morgan, 2017
- [TensorFlow models](https://github.com/tensorflow/models)
- [Structuring Your TensorFlow Models](https://danijar.com/structuring-your-tensorflow-models/), Danijar Hafner, 2016

## Generative Adversarial Network

Reviews & Tutorials

- [The GAN Zoo](https://deephunt.in/the-gan-zoo-79597dc8c347), Avinash Hindupur, 2017
- [Generative Adversarial Nets in TensorFlow](http://wiseodd.github.io/techblog/2016/09/17/gan-tensorflow/), Agustinus Kristiadi, Personal Blog, 2016
- [Collection of Generative Models (GAN & VAE) in Pytorch and Tensorflow](https://github.com/wiseodd/generative-models), Agustinus Kristiadi, Github, 2016
- [How to Train a GAN? Tips and tricks to make GANs work](https://github.com/soumith/ganhacks), Soumith Chintala et al.
- [초짜 대학원생 입장에서 이해하는 GAN 시리즈](http://jaejunyoo.blogspot.com/search/label/GAN), Jaejun Yoo, Personal Blog, 2017
- [Generative Adversarial Networks](https://nips.cc/Conferences/2016/Schedule?showEvent=6202), Ian Goodfellow, NIPS 2016 [[Slide]](https://media.nips.cc/Conferences/2016/Slides/6202-Slides.pdf) [[Paper]](http://datascienceassn.org/sites/default/files/Generative%20Adversarial%20Nets.pdf)

Papers

- [DualGAN: Unsupervised Dual Learning for Image-to-Image Translation](https://arxiv.org/abs/1704.02510), Zili Yi et al., 2017
- [On the Effects of Batch and Weight Normalization in Generative Adversarial Networks](https://arxiv.org/abs/1704.03971), Sitao Xiang et al., 2017
- [BEGAN: Boundary Equilibrium Generative Adversarial Networks](https://arxiv.org/abs/1703.10717), David Berthelot et al., 2017
- [Wasserstein GAN](https://arxiv.org/abs/1701.07875), Martin Arjovsky et al., 2017 #WGAN
- [Unrolled Generative Adversarial Networks](https://arxiv.org/abs/1611.02163), Luke Metz et al., 2016 [[Code]](https://github.com/poolio/unrolled_gan)
- [Generative Adversarial Text to Image Synthesis](https://arxiv.org/abs/1605.05396), Scott Reed et al., ICML, 2016
- [Learning Deep Representations of Fine-grained Visual Descriptions](https://arxiv.org/abs/1605.05395v1), Scott Reed et al., CVPR, 2016 
- [On distinguishability criteria for estimating generative models](https://arxiv.org/abs/1412.6515), Ian J. Goodfellow, ICLR Workshop, 2016
- [Improved Techniques for Training GANs](https://arxiv.org/abs/1606.03498), Tim Salimans et al., arXiv, 2016
- [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434), Alec Radford et al., arXiv, 2016 #DCGAN
- [InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets](https://arxiv.org/abs/1606.03657), Xi Chen et al., 2016 [[Code]](https://github.com/openai/InfoGAN)
- [Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784), Mehdi Mirza et al., 2014
- [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661), Ian J. Goodfellow et al., 2014


## Optimization

Reviews & Tutorials

- [An overview of gradient descent optimization algorithms](http://sebastianruder.com/optimizing-gradient-descent/index.html), Sebastian Ruder, Personal Blog, 2016

Papers

- [Adam: a Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980), Diederik P. Kingma et al., ICLR 2015
- [ADADELTA: AN ADAPTIVE LEARNING RATE METHOD](http://www.matthewzeiler.com/pubs/googleTR2012/googleTR2012.pdf), Matthew D. Zeiler, arXiv, 2012
- [Neural Networks for Machine Learning: Lecture 6a. Overview of mini-batch gradient descent](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf), Geofre Hinton, Coursera, 2012 #RMSProp
- [Random Search for Hyper-Parameter Optimization](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf), James Bergstra et al., JMLR, 2012

## Autoencoder

Reviews & Tutorials

- [초짜 대학원생의 입장에서 이해하는 Auto-Encoding Variational Bayes (VAE)](http://jaejunyoo.blogspot.com/2017/04/auto-encoding-variational-bayes-vae-1.html), Jaejun Yoo, Personal Blog, 2017
- [Adversarial Autoencoders (with Pytorch)](https://blog.paperspace.com/adversarial-autoencoders-with-pytorch/), Felipe, Personal Blog, 2017
- [Tutorial on Variational Autoencoders](https://arxiv.org/abs/1606.05908), Carl Doersch, 2016 

Papers

- [Adversarial Autoencoders](https://arxiv.org/abs/1511.05644), Alireza Makhzani et al., 2015 #AAE
- [Denoising Criterion for Variational Auto-Encoding Framework](https://arxiv.org/abs/1511.06406), Daniel Jiwoong Im et al., 2015 #DAE
- [Semi-Supervised Learning with Deep Generative Models](https://arxiv.org/abs/1406.5298), Diederik P. Kingma et al., NIPS, 2014
- [Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114), Diederik P Kingma et al., 2013 #VAE
- [Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion](http://www.jmlr.org/papers/volume11/vincent10a/vincent10a.pdf), Pascal Vincent et al., JMLR, 2010 #DAE
- [Extracting and composing robust features with denoising autoencoders](https://www.iro.umontreal.ca/~vincentp/Publications/denoising_autoencoders_tr1316.pdf), Pascal Vincent et al., ICML, 2008 #DAE
- [Greedy Layer-Wise Training of Deep Networks](http://papers.nips.cc/paper/3048-greedy-layer-wise-training-of-deep-networks.pdf), Bengio et al., NIPS, 2006 #SAE

## Initialization

- [Understanding the difficulty of training deep feedforward neural networks](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.207.2059&rep=rep1&type=pdf), Xavier Glorot et al., AISTATS, 2010

## Activation Function

- [Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)](https://arxiv.org/abs/1511.07289), Djork-Arné Clevert et al., ICLR, 2016

## Regularization & Normalization

- [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](https://arxiv.org/abs/1512.05287), Yarin Gal et al., NIPS, 2016
- [Batch Normalization 설명 및 구현](https://shuuki4.wordpress.com/2016/01/13/batch-normalization-%EC%84%A4%EB%AA%85-%EB%B0%8F-%EA%B5%AC%ED%98%84/), Beomsu Kim, 2016
- [Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models](https://arxiv.org/abs/1502.03167), Sergey Ioffe et al., ICML, 2015

## Recommendation System

- [Practical Recommendations for Gradient-Based Training of Deep Architectures](https://arxiv.org/abs/1206.5533v2), Yoshua Bengio, 2012

## Music

- [Performance RNN: Generating Music with Expressive Timing and Dynamics](https://magenta.tensorflow.org/performance-rnn), 2017

## Game

- [AlphaGo Pipeline 헤집기](https://shuuki4.wordpress.com/2016/03/11/alphago-alphago-pipeline-%ED%97%A4%EC%A7%91%EA%B8%B0/), Beomsu Kim, 2016

## Reinforcement Learning

- [Reinforcement Learning Summary](https://norman3.github.io/rl/), Kiho Hong, Personal Page, 2016

## Uncategorized

- [Machine Learning 스터디](http://sanghyukchun.github.io/blog/categories/machine-learning-study/), Sanghyuk Chun et al., Perosnal Blog, 2014

